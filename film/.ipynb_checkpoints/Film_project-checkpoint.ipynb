{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "Let's import and explore the dataset\n",
    "\n",
    "There are 15 datasets, namle\n",
    "<ol> \n",
    "    <li>actor</li>\n",
    "    <li>address</li>\n",
    "    <li>category</li>\n",
    "    <li>city</li>\n",
    "    <li>country</li>\n",
    "    <li>customer</li>\n",
    "    <li>film</li>\n",
    "    <li>film_actor</li>\n",
    "    <li>film_category</li>\n",
    "    <li>film_text</li>\n",
    "    <li>language</li>\n",
    "    <li>payment</li>\n",
    "    <li>rental</li>\n",
    "    <li>staff</li>\n",
    "    <li>store</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Let's import pandas and matplotLab\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "print('Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 datasets imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Let's import all the 15 dataset into the jupyter notebook\n",
    "actor_data = pd.read_csv('actor.csv', index_col = 0)\n",
    "address_data = pd.read_csv('address.csv', index_col = 0)\n",
    "category_data = pd.read_csv('category.csv', index_col = 0)\n",
    "city_data = pd.read_csv('city.csv', index_col = 0)\n",
    "country_data = pd.read_csv('country.csv', index_col = 0)\n",
    "customer_data = pd.read_csv('customer.csv', index_col = 0)\n",
    "film_data = pd.read_csv('film.csv', index_col = 0)\n",
    "film_actor_data = pd.read_csv('film_actor.csv', index_col = 0)\n",
    "film_category_data = pd.read_csv('film_category.csv', index_col = 0)\n",
    "film_text_data = pd.read_csv('film_text.csv', index_col = 0)\n",
    "language_data = pd.read_csv('language.csv', index_col = 0)\n",
    "payment_data = pd.read_csv('payment.csv', index_col = 0)\n",
    "rental_data = pd.read_csv('rental.csv', index_col = 0)\n",
    "staff_data = pd.read_csv('staff.csv', index_col = 0)\n",
    "store_data = pd.read_csv('store.csv', index_col = 0)\n",
    "\n",
    "# Let's name each dataFrame\n",
    "actor_data.name = 'actor_data'\n",
    "address_data.name = 'address_data'\n",
    "category_data.name = 'category_data'\n",
    "city_data.name = 'city_data'\n",
    "country_data.name = 'country_data'\n",
    "customer_data.name = 'customer_data'\n",
    "film_data.name = 'film_data'\n",
    "film_actor_data.name = 'film_actor_data'\n",
    "film_category_data.name = 'film_category_data'\n",
    "film_text_data.name = 'film_text_data'\n",
    "language_data.name = 'language_data'\n",
    "payment_data.name = 'payment_data'\n",
    "rental_data.name = 'rental_data'\n",
    "staff_data.name = 'staff_data'\n",
    "store_data.name = 'store_data'\n",
    "print('15 datasets imported successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the tables in an array in order to iterate them\n",
    "array_table = [actor_data, category_data, city_data, country_data, customer_data, film_data, film_actor_data, \n",
    "               film_category_data, film_text_data, language_data, payment_data,rental_data, staff_data, store_data,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the shape of one dataset\n",
    "store_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the shape of all the dataset in a comprehensive datFrame\n",
    "summary_table = pd.DataFrame({'rows':[actor_data.shape[0], address_data.shape[0], category_data.shape[0], \n",
    "                    city_data.shape[0],country_data.shape[0], customer_data.shape[0], film_data.shape[0], \n",
    "                    film_actor_data.shape[0], film_category_data.shape[0], film_text_data.shape[0], language_data.shape[0],\n",
    "                    payment_data.shape[0], rental_data.shape[0], staff_data.shape[0], store_data.shape[0],\n",
    "                       ],\n",
    "              'column':[actor_data.shape[1], address_data.shape[1], category_data.shape[1],\n",
    "                    city_data.shape[1], country_data.shape[1], customer_data.shape[1], film_data.shape[1],\n",
    "                    film_actor_data.shape[1], film_category_data.shape[1], film_text_data.shape[1], language_data.shape[1],\n",
    "                    payment_data.shape[1], rental_data.shape[1], staff_data.shape[1], store_data.shape[1]\n",
    "                       ],\n",
    "             },\n",
    "             index=['actor_data',\n",
    "                    'address_data',\n",
    "                    'category_data',\n",
    "                    'city_data',\n",
    "                    'country_data',\n",
    "                    'customer_data',\n",
    "                    'film_data',\n",
    "                    'film_actor_data',\n",
    "                    'film_category_data',\n",
    "                    'film_text_data',\n",
    "                    'language_data',\n",
    "                    'payment_data',\n",
    "                    'rental_data',\n",
    "                    'staff_data',\n",
    "                    'store_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_missing_data(table):\n",
    "    missing_data = table.isnull()\n",
    "    for column in missing_data.columns.values.tolist():\n",
    "        print(column)\n",
    "        print(missing_data[column].value_counts())\n",
    "        print(\"\")\n",
    "    print(\"-------------- End ---------------------------\", )\n",
    "def summary_all_missing_data(all_table):\n",
    "    for table in all_table:\n",
    "        print(table.name)\n",
    "        summary_missing_data(table)\n",
    "\n",
    "summary_all_missing_data(array_table) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the dataset for missing data, we were able to identify the following: <br>\n",
    "<strong>Payment</strong> dataset has <strong>5</strong> missing  rental_id <br>\n",
    "<strong>Rental</strong> dataset has <strong>183</strong> missing return_date <br>\n",
    "In <strong>Staff</strong> dataset, <strong>one</strong> employee did not attach picture <br>\n",
    "In <strong>Staff</strong> dataset, <strong>one</strong> employee did not have password  <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the fields of different datasets\n",
    "for table in array_table:\n",
    "    table.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>last_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>128</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>PENELOPE</td>\n",
       "      <td>KILMER</td>\n",
       "      <td>2006-02-15 04:34:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       first_name last_name          last_update\n",
       "count         200       200                  200\n",
       "unique        128       121                    1\n",
       "top      PENELOPE    KILMER  2006-02-15 04:34:33\n",
       "freq            4         5                  200"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
